{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92649\n",
      "116\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "trainSet = pd.read_csv('dota2Train.csv')\n",
    "testSet = pd.read_csv('dota2Test.csv')\n",
    "\n",
    "x = trainSet.drop('-1', 1)\n",
    "y = trainSet['-1']\n",
    "xVal = testSet.drop('-1', 1)\n",
    "yVal = testSet['-1']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "n_classes = len(np.unique(y))\n",
    "labels = y\n",
    "sample_size = n_samples * 0.16\n",
    "print n_samples\n",
    "print n_features\n",
    "print n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\t\tK\thomo\tcompl\tv-meas\tARI\tAMI\n",
      "kmeans++\t1\t0.000\t1.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t2\t0.000\t0.000\t0.000\t-0.000\t-0.000\t\n",
      "kmeans++\t5\t0.000\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t10\t0.000\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t15\t0.000\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t20\t0.000\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t30\t0.001\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t40\t0.001\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t50\t0.001\t0.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t100\t0.003\t0.000\t0.001\t0.000\t0.000\t\n",
      "kmeans++\t200\t0.004\t0.000\t0.001\t0.000\t0.000\t\n",
      "kmeans++\t400\t0.006\t0.001\t0.001\t0.000\t0.000\t\n"
     ]
    }
   ],
   "source": [
    "# Procedure 1\n",
    "KList = [1, 2, 5, 10, 15, 20, 30, 40, 50, 100, 200, 400, 800, 1600, 3200]\n",
    "# KList = [6400]\n",
    "print('init\\t\\tK\\thomo\\tcompl\\tv-meas\\tARI\\tAMI')\n",
    "for i in KList:   \n",
    "    clu = KMeans(init='k-means++', n_clusters=i,n_init=10, max_iter = 10000)\n",
    "    # X_reduced = dra.fit_transform(myOriginalDataX)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))\n",
    "for i in KList:  \n",
    "    clu = KMeans(init='random', n_clusters=i, n_init=10, max_iter = 10000)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('random\\t\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure 1\n",
    "KList = [1, 5, 10, 15, 20, 30, 40, 50]\n",
    "print('init\\t\\tK\\thomo\\tcompl\\tv-meas\\tARI\\tAMI')\n",
    "for i in KList:   \n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=i,n_init=10, max_iter = 10000)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))\n",
    "for i in KList:  \n",
    "    clu = GaussianMixture(init_params='random', n_components=i, n_init=10, max_iter = 10000)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('random\\t\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure 2\n",
    "pca = PCA(n_components = 2)\n",
    "ica = FastICA(n_components = 2)\n",
    "rp = GaussianRandomProjection(n_components = 2)\n",
    "nmf = NMF(n_components =2 )\n",
    "\n",
    "pca_x = pca.fit_transform(x)\n",
    "ica_x = ica.fit_transform(x)\n",
    "rp_x = rp.fit_transform(x)\n",
    "nmf_x = nmf.fit_transform(x)\n",
    "print kurtosis(x)\n",
    "print kurtosis(pca_x)\n",
    "print kurtosis(ica_x)\n",
    "print kurtosis(rp_x)\n",
    "print kurtosis(nmf_x)\n",
    "# print('%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t'\n",
    "#      % (kurtosis(x), \n",
    "#         kurtosis(pca_x),\n",
    "#         kurtosis(ica_x),\n",
    "#         kurtosis(rp_x),\n",
    "#         kurtosis(nmf_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure 3\n",
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "        % (i, metrics.homogeneity_score(y, predictions),\n",
    "        metrics.completeness_score(y, predictions),\n",
    "        metrics.v_measure_score(y, predictions),\n",
    "        metrics.adjusted_rand_score(y, predictions),\n",
    "        metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "        % (i, metrics.homogeneity_score(y, predictions),\n",
    "        metrics.completeness_score(y, predictions),\n",
    "        metrics.v_measure_score(y, predictions),\n",
    "        metrics.adjusted_rand_score(y, predictions),\n",
    "        metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure 3\n",
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "      % (i, metrics.homogeneity_score(y, predictions),\n",
    "      metrics.completeness_score(y, predictions),\n",
    "      metrics.v_measure_score(y, predictions),\n",
    "      metrics.adjusted_rand_score(y, predictions),\n",
    "      metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "        % (i, metrics.homogeneity_score(y, predictions),\n",
    "        metrics.completeness_score(y, predictions),\n",
    "        metrics.v_measure_score(y, predictions),\n",
    "        metrics.adjusted_rand_score(y, predictions),\n",
    "        metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure 4\n",
    "xTrain = x\n",
    "yTrain = y\n",
    "\n",
    "pca = PCA(n_components = 5)\n",
    "ica = FastICA(n_components = 5)\n",
    "rp = GaussianRandomProjection(n_components = 9)\n",
    "nmf = NMF(n_components = 1)\n",
    "\n",
    "pca = pca.fit(xTrain)\n",
    "ica = ica.fit(xTrain)\n",
    "rp = rp.fit(xTrain)\n",
    "nmf = nmf.fit(xTrain)\n",
    "\n",
    "pca_xTrain = pca.transform(xTrain)\n",
    "pca_xTest = pca.transform(xVal)\n",
    "ica_xTrain = ica.transform(xTrain)\n",
    "ica_xTest = ica.transform(xVal)\n",
    "rp_xTrain = rp.transform(xTrain)\n",
    "rp_xTest = rp.transform(xVal)\n",
    "nmf_xTrain = nmf.transform(xTrain)\n",
    "nmf_xTest = nmf.transform(xVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 11):\n",
    "    xTrainRound = pca_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 10:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(pca_xTrain, yTrain, test_size=i/10.0)\n",
    "    \n",
    "    mlp = MLPClassifier(activation=\"logistic\", learning_rate=\"constant\", max_iter = 100, hidden_layer_sizes = (200,), alpha=0.0005)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(pca_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(92649 * i / 10.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PCA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 11):\n",
    "    xTrainRound = ica_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 10:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(ica_xTrain, yTrain, test_size=i/10.0)\n",
    "    \n",
    "    mlp = MLPClassifier(activation=\"logistic\", learning_rate=\"constant\", max_iter = 100, hidden_layer_sizes = (200,), alpha=0.0005)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(ica_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(92649 * i / 10.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"ICA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 11):\n",
    "    xTrainRound = rp_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 10:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(rp_xTrain, yTrain, test_size=i/10.0)\n",
    "    \n",
    "    mlp = MLPClassifier(activation=\"logistic\", learning_rate=\"constant\", max_iter = 100, hidden_layer_sizes = (200,), alpha=0.0005)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(rp_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(92649 * i / 10.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"RP Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 11):\n",
    "    xTrainRound = nmf_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 10:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(nmf_xTrain, yTrain, test_size=i/10.0)\n",
    "    \n",
    "    mlp = MLPClassifier(activation=\"logistic\", learning_rate=\"constant\", max_iter = 100, hidden_layer_sizes = (200,), alpha=0.0005)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(nmf_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(92649 * i / 10.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"NMF Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure 5\n",
    "kmeans = KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "em = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "\n",
    "kmeans = kmeans.fit(pca_xTrain)\n",
    "em = em.fit(pca_xTrain)\n",
    "\n",
    "kmeans_xTrain = kmeans.transform(pca_xTrain)\n",
    "kmeans_xTest = kmeans.transform(pca_xTest)\n",
    "em_xTrain = em.predict_proba(pca_xTrain)\n",
    "em_xTest = em.predict_proba(pca_xTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
