{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_estimator_results:\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the training dataset\n",
    "trainSet  = pd.read_csv('train.csv')\n",
    "#Encoding the dataset \n",
    "trainingEncoded = pd.get_dummies(trainSet)\n",
    "x = trainingEncoded.drop(['hand'], axis=1)\n",
    "y = trainingEncoded['hand']\n",
    "#Splitting the datasets to independent training and test splits for later use (randomly)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, \n",
    "                                              y,\n",
    "                                              test_size=.1)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "n_classes = len(np.unique(y.values.tolist()))\n",
    "labels = y.values.tolist()\n",
    "sample_size = 4175\n",
    "\n",
    "### RUN EVERYTHING TILL HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\t\tK\thomo\tcompl\tv-meas\tARI\tAMI\n",
      "kmeans++\t1\t0.000\t1.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t5\t0.002\t0.001\t0.002\t0.000\t0.001\t\n",
      "kmeans++\t10\t0.007\t0.003\t0.004\t0.001\t0.002\t\n",
      "kmeans++\t15\t0.025\t0.009\t0.014\t0.004\t0.008\t\n",
      "kmeans++\t20\t0.031\t0.010\t0.015\t0.003\t0.009\t\n",
      "kmeans++\t30\t0.029\t0.008\t0.013\t0.002\t0.007\t\n",
      "kmeans++\t40\t0.040\t0.011\t0.017\t0.002\t0.009\t\n",
      "kmeans++\t50\t0.040\t0.010\t0.016\t0.002\t0.008\t\n",
      "kmeans++\t100\t0.051\t0.011\t0.018\t0.001\t0.008\t\n",
      "kmeans++\t200\t0.074\t0.014\t0.023\t0.001\t0.009\t\n",
      "kmeans++\t400\t0.103\t0.017\t0.029\t0.000\t0.010\t\n",
      "kmeans++\t800\t0.139\t0.021\t0.036\t0.000\t0.010\t\n",
      "kmeans++\t1600\t0.187\t0.025\t0.044\t0.000\t0.008\t\n",
      "kmeans++\t3200\t0.275\t0.034\t0.060\t0.000\t0.009\t\n",
      "random\t\t1\t0.000\t1.000\t0.000\t0.000\t0.000\t\n",
      "random\t\t5\t0.002\t0.001\t0.001\t0.000\t0.001\t\n",
      "random\t\t10\t0.006\t0.003\t0.004\t0.001\t0.002\t\n",
      "random\t\t15\t0.009\t0.003\t0.005\t0.001\t0.002\t\n",
      "random\t\t20\t0.025\t0.008\t0.012\t0.003\t0.007\t\n",
      "random\t\t30\t0.035\t0.010\t0.016\t0.002\t0.009\t\n",
      "random\t\t40\t0.040\t0.011\t0.017\t0.002\t0.009\t\n",
      "random\t\t50\t0.042\t0.011\t0.017\t0.002\t0.009\t\n",
      "random\t\t100\t0.052\t0.011\t0.018\t0.001\t0.008\t\n",
      "random\t\t200\t0.078\t0.015\t0.024\t0.001\t0.010\t\n",
      "random\t\t400\t0.103\t0.017\t0.029\t0.000\t0.010\t\n",
      "random\t\t800\t0.137\t0.020\t0.035\t0.000\t0.009\t\n",
      "random\t\t1600\t0.185\t0.025\t0.044\t0.000\t0.008\t\n",
      "random\t\t3200\t0.274\t0.034\t0.060\t0.000\t0.009\t\n"
     ]
    }
   ],
   "source": [
    "# Procedure 1\n",
    "KList = [1, 5, 10, 15, 20, 30, 40, 50, 100, 200, 400, 800, 1600, 3200]\n",
    "# KList = [6400]\n",
    "print('init\\t\\tK\\thomo\\tcompl\\tv-meas\\tARI\\tAMI')\n",
    "for i in KList:   \n",
    "    clu = KMeans(init='k-means++', n_clusters=i,n_init=10, max_iter = 10000)\n",
    "    # X_reduced = dra.fit_transform(myOriginalDataX)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))\n",
    "for i in KList:  \n",
    "    clu = KMeans(init='random', n_clusters=i, n_init=10, max_iter = 10000)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('random\\t\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\t\tK\thomo\tcompl\tv-meas\tARI\tAMI\n",
      "kmeans++\t1\t0.000\t1.000\t0.000\t0.000\t0.000\t\n",
      "kmeans++\t5\t0.005\t0.003\t0.004\t0.002\t0.002\t\n",
      "kmeans++\t10\t0.004\t0.002\t0.002\t0.001\t0.001\t\n",
      "kmeans++\t15\t0.009\t0.003\t0.005\t0.001\t0.002\t\n",
      "kmeans++\t20\t0.018\t0.006\t0.009\t0.003\t0.005\t\n",
      "kmeans++\t30\t0.011\t0.004\t0.006\t-0.000\t0.002\t\n",
      "kmeans++\t40\t0.010\t0.003\t0.005\t0.001\t0.001\t\n"
     ]
    }
   ],
   "source": [
    "# Procedure 1\n",
    "KList = [1, 5, 10, 15, 20, 30, 40, 50]\n",
    "print('init\\t\\tK\\thomo\\tcompl\\tv-meas\\tARI\\tAMI')\n",
    "for i in KList:   \n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=i,n_init=10, max_iter = 10000)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))\n",
    "for i in KList:  \n",
    "    clu = GaussianMixture(init_params='random', n_components=i, n_init=10, max_iter = 10000)\n",
    "    clu.fit(x)\n",
    "    predictions = clu.predict(x)\n",
    "    print('random\\t\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.35638799 -1.21538938 -1.36844697 -1.22398552 -1.37159445 -1.22272412\n",
      " -1.35532037 -1.220673   -1.36158138 -1.21460974]\n",
      "[-0.46064017 -0.58876062]\n",
      "[-0.88030839 -0.65733031]\n",
      "[-0.66662766 -0.26876567]\n",
      "[-0.38640927 -0.84028664]\n"
     ]
    }
   ],
   "source": [
    "# Procedure 2\n",
    "pca = PCA(n_components = 2)\n",
    "ica = FastICA(n_components = 2)\n",
    "rp = GaussianRandomProjection(n_components = 2)\n",
    "nmf = NMF(n_components =2 )\n",
    "\n",
    "pca_x = pca.fit_transform(x)\n",
    "ica_x = ica.fit_transform(x)\n",
    "rp_x = rp.fit_transform(x)\n",
    "nmf_x = nmf.fit_transform(x)\n",
    "print kurtosis(x)\n",
    "print kurtosis(pca_x)\n",
    "print kurtosis(ica_x)\n",
    "print kurtosis(rp_x)\n",
    "print kurtosis(nmf_x)\n",
    "# print('%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t'\n",
    "#      % (kurtosis(x), \n",
    "#         kurtosis(pca_x),\n",
    "#         kurtosis(ica_x),\n",
    "#         kurtosis(rp_x),\n",
    "#         kurtosis(nmf_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.007\t0.002\t0.004\t-0.001\t0.001\t\n",
      "kmeans++\t2\t0.017\t0.006\t0.009\t0.000\t0.005\t\n",
      "kmeans++\t3\t0.019\t0.006\t0.009\t0.001\t0.005\t\n",
      "kmeans++\t4\t0.009\t0.003\t0.004\t0.001\t0.002\t\n",
      "kmeans++\t5\t0.033\t0.011\t0.016\t0.003\t0.010\t\n",
      "kmeans++\t6\t0.025\t0.008\t0.012\t0.003\t0.007\t\n",
      "kmeans++\t7\t0.025\t0.008\t0.013\t0.003\t0.007\t\n",
      "kmeans++\t8\t0.027\t0.009\t0.013\t0.003\t0.008\t\n",
      "kmeans++\t9\t0.026\t0.009\t0.013\t0.003\t0.008\t\n",
      "kmeans++\t10\t0.029\t0.010\t0.015\t0.003\t0.009\t\n"
     ]
    }
   ],
   "source": [
    "#Procedure 3\n",
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.007\t0.002\t0.003\t-0.001\t0.001\t\n",
      "random\t2\t0.016\t0.005\t0.008\t0.000\t0.004\t\n",
      "random\t3\t0.018\t0.006\t0.009\t0.001\t0.005\t\n",
      "random\t4\t0.038\t0.013\t0.019\t0.003\t0.011\t\n",
      "random\t5\t0.026\t0.009\t0.013\t0.003\t0.007\t\n",
      "random\t6\t0.025\t0.008\t0.012\t0.003\t0.007\t\n",
      "random\t7\t0.026\t0.009\t0.013\t0.003\t0.007\t\n",
      "random\t8\t0.028\t0.009\t0.014\t0.003\t0.008\t\n",
      "random\t9\t0.028\t0.009\t0.014\t0.003\t0.008\t\n",
      "random\t10\t0.029\t0.010\t0.014\t0.003\t0.008\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.007\t0.002\t0.003\t-0.001\t0.001\t-1.319\n",
      "kmeans++\t2\t0.017\t0.005\t0.008\t0.000\t0.004\t-1.186\n",
      "kmeans++\t3\t0.021\t0.007\t0.010\t0.001\t0.006\t-1.168\n",
      "kmeans++\t4\t0.010\t0.003\t0.005\t0.001\t0.002\t-1.240\n",
      "kmeans++\t5\t0.029\t0.010\t0.014\t0.003\t0.008\t-1.178\n",
      "kmeans++\t6\t0.019\t0.006\t0.009\t0.002\t0.005\t-1.202\n",
      "kmeans++\t7\t0.016\t0.005\t0.008\t0.001\t0.004\t-1.233\n",
      "kmeans++\t8\t0.013\t0.004\t0.006\t0.001\t0.003\t-1.205\n",
      "kmeans++\t9\t0.012\t0.004\t0.006\t0.001\t0.003\t-1.231\n",
      "kmeans++\t10\t0.006\t0.002\t0.003\t0.000\t0.001\t-1.207\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.007\t0.002\t0.004\t-0.001\t0.001\t-0.836\n",
      "random\t2\t0.018\t0.006\t0.009\t0.000\t0.005\t-1.266\n",
      "random\t3\t0.017\t0.005\t0.008\t0.001\t0.004\t-1.203\n",
      "random\t4\t0.011\t0.004\t0.006\t0.001\t0.003\t-1.205\n",
      "random\t5\t0.029\t0.009\t0.014\t0.003\t0.008\t-1.182\n",
      "random\t6\t0.018\t0.006\t0.009\t0.002\t0.005\t-1.219\n",
      "random\t7\t0.015\t0.005\t0.007\t0.001\t0.004\t-1.174\n",
      "random\t8\t0.011\t0.004\t0.006\t0.001\t0.003\t-1.201\n",
      "random\t9\t0.006\t0.002\t0.003\t0.000\t0.001\t-1.210\n",
      "random\t10\t0.007\t0.002\t0.004\t0.000\t0.001\t-1.225\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.005\t0.002\t0.003\t-0.001\t0.001\t\n",
      "kmeans++\t2\t0.004\t0.001\t0.002\t-0.000\t0.000\t\n",
      "kmeans++\t3\t0.010\t0.003\t0.005\t0.000\t0.002\t\n",
      "kmeans++\t4\t0.007\t0.002\t0.004\t-0.000\t0.001\t\n",
      "kmeans++\t5\t0.016\t0.005\t0.008\t0.001\t0.004\t\n",
      "kmeans++\t6\t0.019\t0.006\t0.009\t0.002\t0.005\t\n",
      "kmeans++\t7\t0.017\t0.006\t0.008\t0.001\t0.004\t\n",
      "kmeans++\t8\t0.014\t0.005\t0.007\t0.001\t0.004\t\n",
      "kmeans++\t9\t0.023\t0.008\t0.011\t0.002\t0.006\t\n",
      "kmeans++\t10\t0.015\t0.005\t0.007\t0.001\t0.004\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.003\t0.001\t0.002\t0.000\t0.000\t\n",
      "random\t2\t0.018\t0.006\t0.009\t0.003\t0.005\t\n",
      "random\t3\t0.011\t0.004\t0.006\t0.001\t0.003\t\n",
      "random\t4\t0.019\t0.006\t0.010\t0.002\t0.005\t\n",
      "random\t5\t0.010\t0.003\t0.005\t0.000\t0.002\t\n",
      "random\t6\t0.013\t0.004\t0.006\t0.000\t0.003\t\n",
      "random\t7\t0.013\t0.004\t0.006\t0.001\t0.003\t\n",
      "random\t8\t0.016\t0.005\t0.008\t0.001\t0.004\t\n",
      "random\t9\t0.017\t0.006\t0.009\t0.001\t0.005\t\n",
      "random\t10\t0.022\t0.007\t0.011\t0.002\t0.006\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "        % (i, metrics.homogeneity_score(y, predictions),\n",
    "        metrics.completeness_score(y, predictions),\n",
    "        metrics.v_measure_score(y, predictions),\n",
    "        metrics.adjusted_rand_score(y, predictions),\n",
    "        metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.039\t0.014\t0.020\t0.007\t0.012\t\n",
      "kmeans++\t2\t0.028\t0.009\t0.014\t0.004\t0.008\t\n",
      "kmeans++\t3\t0.021\t0.007\t0.011\t0.002\t0.006\t\n",
      "kmeans++\t4\t0.025\t0.008\t0.013\t0.002\t0.007\t\n",
      "kmeans++\t5\t0.029\t0.009\t0.014\t0.003\t0.008\t\n",
      "kmeans++\t6\t0.029\t0.009\t0.014\t0.003\t0.008\t\n",
      "kmeans++\t7\t0.024\t0.008\t0.012\t0.002\t0.007\t\n",
      "kmeans++\t8\t0.027\t0.009\t0.013\t0.003\t0.008\t\n",
      "kmeans++\t9\t0.028\t0.009\t0.014\t0.003\t0.008\t\n",
      "kmeans++\t10\t0.017\t0.005\t0.008\t0.001\t0.004\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu =  KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.038\t0.013\t0.019\t0.007\t0.012\t\n",
      "random\t2\t0.028\t0.009\t0.014\t0.004\t0.008\t\n",
      "random\t3\t0.024\t0.008\t0.012\t0.002\t0.007\t\n",
      "random\t4\t0.025\t0.008\t0.012\t0.002\t0.007\t\n",
      "random\t5\t0.025\t0.008\t0.012\t0.002\t0.007\t\n",
      "random\t6\t0.023\t0.008\t0.012\t0.002\t0.007\t\n",
      "random\t7\t0.022\t0.007\t0.011\t0.002\t0.006\t\n",
      "random\t8\t0.025\t0.008\t0.012\t0.002\t0.007\t\n",
      "random\t9\t0.023\t0.008\t0.011\t0.003\t0.007\t\n",
      "random\t10\t0.007\t0.002\t0.003\t0.000\t0.001\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu =  KMeans(init='random', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "        % (i, metrics.homogeneity_score(y, predictions),\n",
    "        metrics.completeness_score(y, predictions),\n",
    "        metrics.v_measure_score(y, predictions),\n",
    "        metrics.adjusted_rand_score(y, predictions),\n",
    "        metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.009\t0.003\t0.004\t-0.000\t0.001\t\n",
      "kmeans++\t2\t0.021\t0.006\t0.010\t0.000\t0.005\t\n",
      "kmeans++\t3\t0.021\t0.006\t0.010\t0.001\t0.005\t\n",
      "kmeans++\t4\t0.040\t0.012\t0.018\t0.002\t0.010\t\n",
      "kmeans++\t5\t0.014\t0.004\t0.007\t0.001\t0.003\t\n",
      "kmeans++\t6\t0.013\t0.004\t0.006\t0.001\t0.003\t\n",
      "kmeans++\t7\t0.008\t0.003\t0.004\t-0.000\t0.001\t\n",
      "kmeans++\t8\t0.017\t0.005\t0.008\t0.002\t0.004\t\n",
      "kmeans++\t9\t0.017\t0.005\t0.008\t0.002\t0.004\t\n",
      "kmeans++\t10\t0.017\t0.005\t0.008\t0.001\t0.004\t\n"
     ]
    }
   ],
   "source": [
    "#Procedure 3\n",
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.004\t0.003\t0.003\t-0.007\t0.002\t\n",
      "random\t2\t0.008\t0.004\t0.005\t0.000\t0.003\t\n",
      "random\t3\t0.011\t0.005\t0.007\t-0.001\t0.003\t\n",
      "random\t4\t0.009\t0.004\t0.005\t-0.005\t0.002\t\n",
      "random\t5\t0.017\t0.006\t0.009\t0.000\t0.004\t\n",
      "random\t6\t0.016\t0.005\t0.008\t0.002\t0.004\t\n",
      "random\t7\t0.013\t0.004\t0.006\t0.000\t0.003\t\n",
      "random\t8\t0.014\t0.005\t0.007\t0.002\t0.003\t\n",
      "random\t9\t0.010\t0.003\t0.005\t0.000\t0.001\t\n",
      "random\t10\t0.009\t0.003\t0.004\t0.000\t0.001\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = PCA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.009\t0.003\t0.004\t-0.001\t0.001\t-1.140\n",
      "kmeans++\t2\t0.020\t0.006\t0.009\t0.000\t0.005\t-1.308\n",
      "kmeans++\t3\t0.023\t0.007\t0.010\t0.000\t0.005\t-1.171\n",
      "kmeans++\t4\t0.043\t0.013\t0.019\t0.003\t0.011\t-1.226\n",
      "kmeans++\t5\t0.035\t0.010\t0.016\t0.003\t0.009\t-1.212\n",
      "kmeans++\t6\t0.025\t0.007\t0.011\t0.002\t0.006\t-1.233\n",
      "kmeans++\t7\t0.021\t0.006\t0.009\t0.002\t0.005\t-1.260\n",
      "kmeans++\t8\t0.015\t0.004\t0.007\t0.001\t0.003\t-1.235\n",
      "kmeans++\t9\t0.012\t0.003\t0.005\t0.001\t0.002\t-1.286\n",
      "kmeans++\t10\t0.009\t0.003\t0.004\t0.000\t0.001\t-0.844\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.002\t0.002\t0.002\t-0.003\t0.002\t-0.529\n",
      "random\t2\t0.010\t0.005\t0.007\t-0.004\t0.004\t-1.236\n",
      "random\t3\t0.007\t0.003\t0.005\t-0.004\t0.002\t-0.835\n",
      "random\t4\t0.010\t0.004\t0.006\t-0.003\t0.003\t-1.178\n",
      "random\t5\t0.016\t0.006\t0.009\t0.001\t0.004\t-1.038\n",
      "random\t6\t0.013\t0.004\t0.006\t-0.000\t0.003\t-1.137\n",
      "random\t7\t0.015\t0.005\t0.007\t-0.000\t0.003\t-1.296\n",
      "random\t8\t0.015\t0.005\t0.007\t0.002\t0.003\t-1.231\n",
      "random\t9\t0.010\t0.003\t0.005\t0.001\t0.002\t-1.115\n",
      "random\t10\t0.010\t0.003\t0.004\t-0.000\t0.001\t-1.132\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = FastICA(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions),\n",
    "            kurtosis(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.025\t0.007\t0.011\t0.003\t0.006\t\n",
      "kmeans++\t2\t0.008\t0.002\t0.004\t-0.000\t0.001\t\n",
      "kmeans++\t3\t0.009\t0.003\t0.004\t-0.000\t0.001\t\n",
      "kmeans++\t4\t0.010\t0.003\t0.005\t0.000\t0.001\t\n",
      "kmeans++\t5\t0.023\t0.007\t0.011\t0.002\t0.005\t\n",
      "kmeans++\t6\t0.014\t0.004\t0.006\t0.001\t0.003\t\n",
      "kmeans++\t7\t0.014\t0.004\t0.007\t0.000\t0.003\t\n",
      "kmeans++\t8\t0.014\t0.004\t0.006\t0.001\t0.003\t\n",
      "kmeans++\t9\t0.016\t0.005\t0.008\t0.001\t0.003\t\n",
      "kmeans++\t10\t0.007\t0.002\t0.004\t-0.000\t0.001\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.001\t0.001\t0.001\t0.003\t0.001\t\n",
      "random\t2\t0.004\t0.002\t0.002\t-0.001\t0.001\t\n",
      "random\t3\t0.005\t0.002\t0.003\t0.001\t0.001\t\n",
      "random\t4\t0.008\t0.003\t0.004\t-0.001\t0.001\t\n",
      "random\t5\t0.014\t0.005\t0.007\t0.001\t0.003\t\n",
      "random\t6\t0.012\t0.004\t0.006\t0.000\t0.003\t\n",
      "random\t7\t0.012\t0.004\t0.006\t0.001\t0.002\t\n",
      "random\t8\t0.012\t0.004\t0.006\t0.001\t0.002\t\n",
      "random\t9\t0.008\t0.003\t0.004\t0.001\t0.001\t\n",
      "random\t10\t0.011\t0.003\t0.005\t0.000\t0.002\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = GaussianRandomProjection(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "      % (i, metrics.homogeneity_score(y, predictions),\n",
    "      metrics.completeness_score(y, predictions),\n",
    "      metrics.v_measure_score(y, predictions),\n",
    "      metrics.adjusted_rand_score(y, predictions),\n",
    "      metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans++\t1\t0.041\t0.013\t0.019\t0.006\t0.011\t\n",
      "kmeans++\t2\t0.033\t0.010\t0.015\t0.003\t0.008\t\n",
      "kmeans++\t3\t0.015\t0.005\t0.007\t0.001\t0.003\t\n",
      "kmeans++\t4\t0.015\t0.005\t0.007\t0.001\t0.003\t\n",
      "kmeans++\t5\t0.014\t0.004\t0.007\t0.002\t0.003\t\n",
      "kmeans++\t6\t0.010\t0.003\t0.005\t0.000\t0.002\t\n",
      "kmeans++\t7\t0.017\t0.005\t0.008\t0.001\t0.004\t\n",
      "kmeans++\t8\t0.013\t0.004\t0.006\t0.001\t0.003\t\n",
      "kmeans++\t9\t0.012\t0.004\t0.006\t0.001\t0.002\t\n",
      "kmeans++\t10\t0.006\t0.002\t0.003\t0.001\t0.001\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('kmeans++\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "          % (i, metrics.homogeneity_score(y, predictions),\n",
    "          metrics.completeness_score(y, predictions),\n",
    "          metrics.v_measure_score(y, predictions),\n",
    "          metrics.adjusted_rand_score(y, predictions),\n",
    "          metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\t1\t0.024\t0.022\t0.023\t0.042\t0.021\t\n",
      "random\t2\t0.011\t0.008\t0.009\t0.007\t0.007\t\n",
      "random\t3\t0.019\t0.008\t0.011\t0.002\t0.007\t\n",
      "random\t4\t0.018\t0.007\t0.010\t0.004\t0.006\t\n",
      "random\t5\t0.015\t0.005\t0.008\t0.000\t0.004\t\n",
      "random\t6\t0.014\t0.005\t0.007\t0.002\t0.003\t\n",
      "random\t7\t0.015\t0.005\t0.007\t0.001\t0.003\t\n",
      "random\t8\t0.013\t0.004\t0.006\t-0.001\t0.002\t\n",
      "random\t9\t0.014\t0.004\t0.006\t0.001\t0.003\t\n",
      "random\t10\t0.008\t0.002\t0.004\t0.000\t0.001\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    dra = NMF(n_components=i)\n",
    "    clu = GaussianMixture(init_params='random', n_components=30,n_init=10, max_iter = 10000)\n",
    "    X_reduced = dra.fit_transform(x)\n",
    "    clu.fit(X_reduced)\n",
    "    predictions = clu.predict(X_reduced)\n",
    "    print('random\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t' \n",
    "        % (i, metrics.homogeneity_score(y, predictions),\n",
    "        metrics.completeness_score(y, predictions),\n",
    "        metrics.v_measure_score(y, predictions),\n",
    "        metrics.adjusted_rand_score(y, predictions),\n",
    "        metrics.adjusted_mutual_info_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure 4\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, \n",
    "                                              y,\n",
    "                                              test_size=.1)\n",
    "\n",
    "pca = PCA(n_components = 5)\n",
    "ica = FastICA(n_components = 5)\n",
    "rp = GaussianRandomProjection(n_components = 9)\n",
    "nmf = NMF(n_components = 1)\n",
    "\n",
    "pca = pca.fit(xTrain)\n",
    "ica = ica.fit(xTrain)\n",
    "rp = rp.fit(xTrain)\n",
    "nmf = nmf.fit(xTrain)\n",
    "\n",
    "pca_xTrain = pca.transform(xTrain)\n",
    "pca_xTest = pca.transform(xVal)\n",
    "ica_xTrain = ica.transform(xTrain)\n",
    "ica_xTest = ica.transform(xVal)\n",
    "rp_xTrain = rp.transform(xTrain)\n",
    "rp_xTest = rp.transform(xVal)\n",
    "nmf_xTrain = nmf.transform(xTrain)\n",
    "nmf_xTest = nmf.transform(xVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = pca_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(pca_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(pca_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PCA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = ica_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(ica_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(ica_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"ICA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = rp_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(rp_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(rp_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"RP Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = nmf_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(nmf_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(nmf_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"NMF Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure 5\n",
    "kmeans = KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "em = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "\n",
    "kmeans = kmeans.fit(pca_xTrain)\n",
    "em = em.fit(pca_xTrain)\n",
    "\n",
    "kmeans_xTrain = kmeans.transform(pca_xTrain)\n",
    "kmeans_xTest = kmeans.transform(pca_xTest)\n",
    "em_xTrain = em.predict_proba(pca_xTrain)\n",
    "em_xTest = em.predict_proba(pca_xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = kmeans_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(kmeans_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(kmeans_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KMeans-PCA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = em_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(em_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(em_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"EM-PCA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "em = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "\n",
    "kmeans = kmeans.fit(ica_xTrain)\n",
    "em = em.fit(ica_xTrain)\n",
    "\n",
    "kmeans_xTrain = kmeans.transform(ica_xTrain)\n",
    "kmeans_xTest = kmeans.transform(ica_xTest)\n",
    "em_xTrain = em.predict_proba(ica_xTrain)\n",
    "em_xTest = em.predict_proba(ica_xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = kmeans_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(kmeans_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(kmeans_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KMeans-ICA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = em_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(em_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(em_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"EM-ICA Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "em = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "\n",
    "kmeans = kmeans.fit(rp_xTrain)\n",
    "em = em.fit(rp_xTrain)\n",
    "\n",
    "kmeans_xTrain = kmeans.transform(rp_xTrain)\n",
    "kmeans_xTest = kmeans.transform(rp_xTest)\n",
    "em_xTrain = em.predict_proba(rp_xTrain)\n",
    "em_xTest = em.predict_proba(rp_xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = kmeans_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(kmeans_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(kmeans_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KMeans-RP Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = em_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(em_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(em_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"EM-RP Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=20,n_init=10, max_iter = 10000)\n",
    "em = GaussianMixture(init_params='kmeans', n_components=30,n_init=10, max_iter = 10000)\n",
    "\n",
    "kmeans = kmeans.fit(nmf_xTrain)\n",
    "em = em.fit(nmf_xTrain)\n",
    "\n",
    "kmeans_xTrain = kmeans.transform(nmf_xTrain)\n",
    "kmeans_xTest = kmeans.transform(nmf_xTest)\n",
    "em_xTrain = em.predict_proba(nmf_xTrain)\n",
    "em_xTest = em.predict_proba(nmf_xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = kmeans_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(kmeans_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(kmeans_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KMeans-NMF Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST ERROR MEASURER #### RUN THIS #####\n",
    "sampleNum = []\n",
    "trainScoreArr = []\n",
    "testScoreArr = []\n",
    "index = -1\n",
    "bestScore = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    xTrainRound = em_xTrain\n",
    "    yTrainRound = yTrain\n",
    "    if i < 5:\n",
    "        xTrainRound, throwaway1, yTrainRound, throwaway2 = train_test_split(em_xTrain, yTrain, test_size=i/5.0)\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (500,), learning_rate=\"constant\", activation='relu', alpha =0.0008)\n",
    "    mlp.fit(xTrainRound, yTrainRound)\n",
    "    \n",
    "    trainPredRes = mlp.predict(xTrainRound)\n",
    "    trainPredRes = pd.DataFrame(data=trainPredRes, columns=['hand'])\n",
    "    trainAcc = accuracy_score(yTrainRound, trainPredRes)\n",
    "    \n",
    "    testPredRes = mlp.predict(em_xTest)\n",
    "    testPredRes = pd.DataFrame(data=testPredRes, columns=['hand'])\n",
    "    testAcc = accuracy_score(yVal, testPredRes)\n",
    "    \n",
    "    if testAcc > bestScore:\n",
    "        index = i\n",
    "        bestScore = testAcc\n",
    "    trainScoreArr.append(trainAcc)\n",
    "    testScoreArr.append(testAcc)\n",
    "    sampleNum.append(22509 * i / 5.0)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"EM-NMF Train Test Error\")\n",
    "plt.xlabel(\"Num of Samples\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(sampleNum, testScoreArr, 'o-', color=\"r\", label = \"Testing Score\")\n",
    "plt.plot(sampleNum, trainScoreArr, 'o-', color=\"g\", label = \"Training Score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
